# -*- coding: utf-8 -*-
"""Copy of DCGANnew.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Mxm0hImoXPYJByXHrEd3jMalJbBvVt7t
"""

!pip install tensorflow-datasets

import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
import tensorflow as tf

ds=tfds.load("celeb_a",split="train")

import numpy as np

dataiterator =ds.as_numpy_iterator()#set up connection

import cv2

fig,ax=plt.subplots(ncols=4,figsize=(20,20))
for idx in range(4):
  batch=dataiterator.next()
  ax[idx].imshow(np.squeeze(batch["image"]))

def scale_image(data):
  image=data["image"]
  image=tf.image.resize(image,[56,56])
  return image/255

ds=ds.map(scale_image)
ds=ds.cache()
ds=ds.shuffle(60000)
ds=ds.batch(32)
ds=ds.prefetch(64)



from tensorflow.keras import layers

from keras.api._v2.keras import activations
def make_generator_model():
    model = tf.keras.Sequential()
    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Reshape((7, 7, 256)))
    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size

    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))
    assert model.output_shape == (None, 7, 7, 128)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))
    assert model.output_shape == (None, 14, 14, 64)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False,))
    assert model.output_shape == (None, 28, 28, 32)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False,activation="tanh"))
    assert model.output_shape == (None, 56, 56, 3)

    return model

generator= make_generator_model()

generator.summary()

import tensorflow as tf

img123=generator(tf.random.normal([1, 100]))

generator=tf.keras.models.load_model("generator2.h5")
discriminator=tf.keras.models.load_model("discriminator2.h5")

def make_discriminator_model():
    model = tf.keras.Sequential()
    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',
                                     input_shape=[56, 56, 3]))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Flatten())
    model.add(layers.Dense(1))

    return model

discriminator=make_discriminator_model()

discriminator.summary()

cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def discriminator_loss(real_output,fake_output):
  real_loss=cross_entropy(tf.ones_like(real_output),real_output)
  fake_loss=cross_entropy(tf.zeros_like(fake_output),fake_output)
  total_loss=real_loss+fake_loss
  return total_loss



def generator_loss(fake_output):
  total_loss=cross_entropy(tf.ones_like(fake_output),fake_output)
  return total_loss



from tensorflow.keras.optimizers import Adam

generator_optimizer = Adam(1e-4)
discriminator_optimizer = Adam(1e-4)

class DCGAN(tf.keras.models.Model):
  def __init__(self,generator,discriminator,*args,**kwargs):
    super().__init__(*args,**kwargs)
    self.generator=generator
    self.discriminator=discriminator

  def compile(self,generator_optimizer,discriminator_optimizer,g_loss,d_loss,*args,**kwargs):
    super().compile(*args,**kwargs)
    self.g_opt=generator_optimizer
    self.d_opt=discriminator_optimizer
    self.g_loss=g_loss
    self.d_loss=d_loss

  def train_step(self,image):
    real_image=image
    noise=tf.random.normal([16,100])
    with tf.GradientTape() as gen_tape,  tf.GradientTape() as disc_tape:
      generated_image=self.generator(noise,training=True)
      real_output=self.discriminator(image,training=True)
      fake_output=self.discriminator(generated_image,training=True)

      gen_loss=self.g_loss(fake_output)
      disc_loss=self.d_loss(real_output,fake_output)
    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

    return  {"d_loss":gen_loss,"g_loss":disc_loss}

model=DCGAN(generator,discriminator)

model.compile(generator_optimizer,discriminator_optimizer,generator_loss,discriminator_loss)



from tensorflow.keras.preprocessing.image import array_to_img
from tensorflow.keras.callbacks import Callback
import os

class ModelMoniter(Callback):
  def __init__(self,num_img=3,latent_dim=100):
    self.num_img=num_img
    self.latent_dim=latent_dim

  def on_epoch_end(self,epoch,logs=None):
    random_latent_vectors=tf.random.uniform((self.num_img,self.latent_dim,1))
    generated_images=self.model.generator(random_latent_vectors)
    generated_images+=255
    generated_images.numpy()
    for i in range(self.num_img):
      img=array_to_img(generated_images[i])
      img.save(os.path.join("images1",f"generated_img_{epoch}_{i}.png"))

print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))



hist=model.fit(ds,epochs=200,callbacks=[ModelMoniter()])

generator.save("generator5.h5")
discriminator.save("discriminator5.h5")

